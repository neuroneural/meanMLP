{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from apto.utils.misc import boolean_flag\n",
    "from apto.utils.report import get_classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from animus import EarlyStoppingCallback, IExperiment\n",
    "from animus.torch.callbacks import TorchCheckpointerCallback\n",
    "import wandb\n",
    "\n",
    "from src.settings import LOGS_ROOT, UTCNOW\n",
    "from src.ts_data import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (311, 140, 53)\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_dataset('fbirn')\n",
    "features = np.swapaxes(features, 1, 2)  # [n_features; time_len; n_channels;]\n",
    "\n",
    "\n",
    "data_shape = features.shape  # [n_features; time_len; n_channels;]\n",
    "n_classes = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"data shape: \", data_shape)\n",
    "# train-val/test split\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(features, labels)\n",
    "\n",
    "train_index, test_index = list(skf.split(features, labels))[0]\n",
    "\n",
    "X_train, X_test = features[train_index], features[test_index]\n",
    "y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "# train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=data_shape[0] // 5,\n",
    "    random_state=42 + 0,\n",
    "    stratify=y_train,\n",
    ")\n",
    "\n",
    "_train_ds = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.int64),\n",
    ")\n",
    "_valid_ds = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.int64),\n",
    ")\n",
    "_test_ds = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.int64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"train\": DataLoader(\n",
    "        _train_ds,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        _valid_ds,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    ),\n",
    "    \"test\": DataLoader(\n",
    "        _test_ds,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/pavalipopov/230110.002536-tune-mlp-fbirn/runs/cxwzwof3\n"
     ]
    }
   ],
   "source": [
    "from src.ts_model import MLP\n",
    "\n",
    "best_config_path = \"/Users/pavelpopov/mlp_project/assets/logs/230110.022223-experiment-mlp-fbirn/k_0/0000/config.json\"\n",
    "with open(best_config_path, \"r\") as fp:\n",
    "    model_config = json.load(fp)\n",
    "\n",
    "_model = MLP(model_config)\n",
    "\n",
    "logpath = \"/Users/pavelpopov/mlp_project/assets/logs/230110.022223-experiment-mlp-fbirn/k_0/0000/_model.best.pth\"\n",
    "checkpoint = torch.load(logpath, map_location=lambda storage, loc: storage)\n",
    "_model.load_state_dict(checkpoint)\n",
    "\n",
    "print(model_config[\"link\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuned test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores, all_targets = [], []\n",
    "total_loss = 0.0\n",
    "_model.train(False)\n",
    "\n",
    "\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for _, data in enumerate(datasets[\"test\"]):\n",
    "        data, target = data\n",
    "\n",
    "        logits = _model(data)\n",
    "        score = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        all_scores.append(score.cpu().detach().numpy())\n",
    "        all_targets.append(target.cpu().detach().numpy())\n",
    "\n",
    "y_test_test = np.hstack(all_targets)\n",
    "y_score_test = np.vstack(all_scores)\n",
    "y_pred_test = np.argmax(y_score_test, axis=-1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned acc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7301587301587301"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Untuned acc\")\n",
    "accuracy_score(y_test_test, y_pred_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned val acc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6451612903225806"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores, all_targets = [], []\n",
    "total_loss = 0.0\n",
    "_model.train(False)\n",
    "\n",
    "\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for _, data in enumerate(datasets[\"valid\"]):\n",
    "        data, target = data\n",
    "\n",
    "        logits = _model(data)\n",
    "        score = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        all_scores.append(score.cpu().detach().numpy())\n",
    "        all_targets.append(target.cpu().detach().numpy())\n",
    "\n",
    "y_test = np.hstack(all_targets)\n",
    "y_score = np.vstack(all_scores)\n",
    "y_pred = np.argmax(y_score, axis=-1).astype(np.int32)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Untuned val acc\")\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62,)\n",
      "(62, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thr_gen(depth, sum, constr_threshold):\n",
    "    if depth == 1:\n",
    "        yield constr_threshold + [sum]\n",
    "        return\n",
    "    for thr in np.arange(0.0, sum+0.0001, 0.001):\n",
    "        rest_sum = sum - thr\n",
    "        if rest_sum >= 0.0:\n",
    "            new_constr_threshold = constr_threshold + [thr]\n",
    "            yield from thr_gen(depth-1, rest_sum, new_constr_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "Tuned val acc\n",
      "0.6935483870967742\n",
      "[0.26768421 0.73231579]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2 \n",
    "\n",
    "best_acc = 0.0\n",
    "best_threshold = [np.array(([0]*n_classes))]\n",
    "\n",
    "for thr in thr_gen(n_classes, 1.0, []):\n",
    "    thr = np.array(thr)\n",
    "\n",
    "    new_y_score = y_score - thr\n",
    "\n",
    "    y_pred = np.argmax(new_y_score, axis=-1).astype(np.int32)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = [thr]\n",
    "    elif acc == best_acc:\n",
    "        best_threshold += [thr]\n",
    "\n",
    "best_threshold = np.mean(np.stack(best_threshold), axis=0)\n",
    "print(best_threshold.shape)\n",
    "print(\"Tuned val acc\")\n",
    "print(best_acc)\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_score_test = y_score_test - best_threshold\n",
    "new_y_pred_test = np.argmax(new_y_score_test, axis=-1).astype(np.int32)\n",
    "accuracy_score(y_test_test, new_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned val acc\n",
      "0.6935483870967742\n",
      "[0.184 0.629]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2 \n",
    "\n",
    "best_threshold = np.array(([0.0]*n_classes))\n",
    "\n",
    "for tuned_class in range(n_classes):\n",
    "    best_acc = 0.0\n",
    "    threshold = best_threshold.copy()\n",
    "    for thr in np.arange(0.0, 1.0, 0.001):\n",
    "        threshold[tuned_class] = thr\n",
    "\n",
    "        new_y_score = y_score - threshold\n",
    "\n",
    "        # print(new_y_score[0])\n",
    "        y_pred = np.argmax(new_y_score, axis=-1).astype(np.int32)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold[tuned_class] = thr\n",
    "\n",
    "new_y_score = y_score - best_threshold\n",
    "y_pred = np.argmax(new_y_score, axis=-1).astype(np.int32)\n",
    "best_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Tuned val acc\")\n",
    "print(best_acc)\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984126984126984"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_score_test = y_score_test - best_threshold\n",
    "new_y_pred_test = np.argmax(new_y_score_test, axis=-1).astype(np.int32)\n",
    "accuracy_score(y_test_test, new_y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b99d877adb0b7ab3fa56a43902a76f28d27732ee5cf08679707ced7dcdfd859"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
